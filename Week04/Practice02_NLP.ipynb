{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in csv file and create Dataframe & check shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html><h2>What is nlp??? </h2></html> \\nNatural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\\nThe study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\\n(In this post), you will discover what natural language processing is and why it is so important.\\nAfter reading this post, you will know => What natural language is and how it is different from other types of data.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_data = \"\"\"<html><h2>What is nlp??? </h2></html> \n",
    "Natural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\n",
    "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\n",
    "(In this post), you will discover what natural language processing is and why it is so important.\n",
    "After reading this post, you will know => What natural language is and how it is different from other types of data.\"\"\"\n",
    "str_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Cleaning - Remove HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is nlp???  \n",
      "Natural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\n",
      "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\n",
      "(In this post), you will discover what natural language processing is and why it is so important.\n",
      "After reading this post, you will know => What natural language is and how it is different from other types of data.\n"
     ]
    }
   ],
   "source": [
    "def remove_html(text_data):\n",
    "    soup = BeautifulSoup(text_data, 'lxml')\n",
    "    return soup.get_text()\n",
    "\n",
    "processed_text = remove_html(str_data)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Cleaning - Remove punctuation & Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "## Check English's punctuation\n",
    "print('Punctuation: ', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    sent = []\n",
    "    for t in text.split(' '):\n",
    "        no_punct = \"\".join([c for c in t if c not in string.punctuation])\n",
    "        sent.append(no_punct)\n",
    "    \n",
    "    sentence = \" \".join(s for s in sent)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is nlp  \n",
      "Natural Language Processing or NLP for short is broadly defined as the automatic manipulation of natural language like speech and text by software\n",
      "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\n",
      "In this post you will discover what natural language processing is and why it is so important\n",
      "After reading this post you will know  What natural language is and how it is different from other types of data\n"
     ]
    }
   ],
   "source": [
    "rmv_punc_sentence = remove_punctuation(processed_text)\n",
    "print(rmv_punc_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is nlp  \\nnatural language processing or nlp for short is broadly defined as the automatic manipulation of natural language like speech and text by software\\nthe study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\\nin this post you will discover what natural language processing is and why it is so important\\nafter reading this post you will know  what natural language is and how it is different from other types of data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_sentence = rmv_punc_sentence.lower()\n",
    "lower_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Lemmatization & Tokenization with spacy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using \"spacy\" library\n",
    "import spacy\n",
    "\n",
    "## Load the installed model \"en_core_web_sm\" into \"nlp\"\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 'doc' is a sequence of Token objects \n",
    "## it holds all information about the tokens, their linguistic features and their relationships.\n",
    "doc = nlp(lower_sentence.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is nlp  \\nnatural language processing or nlp for short is broadly defined as the automatic manipulation of natural language like speech and text by software\\nthe study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\\nin this post you will discover what natural language processing is and why it is so important\\nafter reading this post you will know  what natural language is and how it is different from other types of data'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what is nlp  \n",
       "natural language processing or nlp for short is broadly defined as the automatic manipulation of natural language like speech and text by software\n",
       "the study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\n",
       "in this post you will discover what natural language processing is and why it is so important\n",
       "after reading this post you will know  what natural language is and how it is different from other types of data"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'what'),\n",
       " ('is', 'be'),\n",
       " ('nlp', 'nlp'),\n",
       " (' \\n', ' \\n'),\n",
       " ('natural', 'natural'),\n",
       " ('language', 'language'),\n",
       " ('processing', 'processing'),\n",
       " ('or', 'or'),\n",
       " ('nlp', 'nlp'),\n",
       " ('for', 'for'),\n",
       " ('short', 'short'),\n",
       " ('is', 'be'),\n",
       " ('broadly', 'broadly'),\n",
       " ('defined', 'define'),\n",
       " ('as', 'as')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_lem_sentence = [(token.text, token.lemma_) for token in doc]\n",
    "tok_lem_sentence[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'be',\n",
       " 'nlp',\n",
       " ' \\n',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'or',\n",
       " 'nlp',\n",
       " 'for',\n",
       " 'short',\n",
       " 'be',\n",
       " 'broadly',\n",
       " 'define',\n",
       " 'as']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_lem_sentence = [token.lemma_ for token in doc]\n",
    "tok_lem_sentence[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# import nltk.corpus\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "print(stopwords.words('english')[:10])\n",
    "print(len(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'be', 'nlp', ' \\n', 'natural', 'language', 'processing', 'or', 'nlp', 'for', 'short', 'be', 'broadly', 'define', 'as', 'the', 'automatic', 'manipulation', 'of', 'natural', 'language', 'like', 'speech', 'and', 'text', 'by', 'software', '\\n', 'the', 'study', 'of', 'natural', 'language', 'processing', 'have', 'be', 'around', 'for', 'more', 'than', '50', 'year', 'and', 'grow', 'out', 'of', 'the', 'field', 'of', 'linguistic', 'with', 'the', 'rise', 'of', 'computer', '\\n', 'in', 'this', 'post', 'you', 'will', 'discover', 'what', 'natural', 'language', 'processing', 'be', 'and', 'why', 'it', 'be', 'so', 'important', '\\n', 'after', 'read', 'this', 'post', 'you', 'will', 'know', ' ', 'what', 'natural', 'language', 'be', 'and', 'how', 'it', 'be', 'different', 'from', 'other', 'type', 'of', 'datum'] \n",
      "\n",
      "['nlp', ' \\n', 'natural', 'language', 'processing', 'nlp', 'short', 'broadly', 'define', 'automatic', 'manipulation', 'natural', 'language', 'like', 'speech', 'text', 'software', '\\n', 'study', 'natural', 'language', 'processing', 'around', '50', 'year', 'grow', 'field', 'linguistic', 'rise', 'computer', '\\n', 'post', 'discover', 'natural', 'language', 'processing', 'important', '\\n', 'read', 'post', 'know', ' ', 'natural', 'language', 'different', 'type', 'datum']\n",
      "\n",
      "Removed word:  {'and', 'with', 'after', 'for', 'it', 'what', 'of', 'in', 'be', 'from', 'the', 'other', 'or', 'so', 'by', 'as', 'how', 'will', 'this', 'why', 'have', 'more', 'you', 'out', 'than'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords  \n",
    "\n",
    "stop_words = set(stopwords.words('english'))  \n",
    "\n",
    "print(tok_lem_sentence, '\\n')\n",
    "rmv_sw_sentence = [w for w in tok_lem_sentence if not w in stop_words]\n",
    "print(rmv_sw_sentence)\n",
    "removed_word = [w for w in tok_lem_sentence if not w in rmv_sw_sentence]\n",
    "print(\"\\nRemoved word: \", set(removed_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dictionary = {}\n",
    "\n",
    "def make_frequency_dict(text):\n",
    "    for word in text:\n",
    "        if word not in dictionary:\n",
    "            dictionary[word] = 0\n",
    "        dictionary[word] += 1\n",
    "            \n",
    "make_frequency_dict(rmv_sw_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nlp': 2,\n",
       " ' \\n': 1,\n",
       " 'natural': 5,\n",
       " 'language': 5,\n",
       " 'processing': 3,\n",
       " 'short': 1,\n",
       " 'broadly': 1,\n",
       " 'define': 1,\n",
       " 'automatic': 1,\n",
       " 'manipulation': 1,\n",
       " 'like': 1,\n",
       " 'speech': 1,\n",
       " 'text': 1,\n",
       " 'software': 1,\n",
       " '\\n': 3,\n",
       " 'study': 1,\n",
       " 'around': 1,\n",
       " '50': 1,\n",
       " 'year': 1,\n",
       " 'grow': 1,\n",
       " 'field': 1,\n",
       " 'linguistic': 1,\n",
       " 'rise': 1,\n",
       " 'computer': 1,\n",
       " 'post': 2,\n",
       " 'discover': 1,\n",
       " 'important': 1,\n",
       " 'read': 1,\n",
       " 'know': 1,\n",
       " ' ': 1,\n",
       " 'different': 1,\n",
       " 'type': 1,\n",
       " 'datum': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural', 5),\n",
       " ('language', 5),\n",
       " ('processing', 3),\n",
       " ('\\n', 3),\n",
       " ('nlp', 2),\n",
       " ('post', 2),\n",
       " (' \\n', 1),\n",
       " ('short', 1),\n",
       " ('broadly', 1),\n",
       " ('define', 1),\n",
       " ('automatic', 1),\n",
       " ('manipulation', 1),\n",
       " ('like', 1),\n",
       " ('speech', 1),\n",
       " ('text', 1),\n",
       " ('software', 1),\n",
       " ('study', 1),\n",
       " ('around', 1),\n",
       " ('50', 1),\n",
       " ('year', 1),\n",
       " ('grow', 1),\n",
       " ('field', 1),\n",
       " ('linguistic', 1),\n",
       " ('rise', 1),\n",
       " ('computer', 1),\n",
       " ('discover', 1),\n",
       " ('important', 1),\n",
       " ('read', 1),\n",
       " ('know', 1),\n",
       " (' ', 1),\n",
       " ('different', 1),\n",
       " ('type', 1),\n",
       " ('datum', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_sorted = sorted(dictionary.items(), key=lambda x:x[1], reverse = True)\n",
    "vocab_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'natural': 1, 'language': 2, 'processing': 3, '\\n': 4, 'nlp': 5, 'post': 6}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "i = 0\n",
    "\n",
    "for (word, frequency) in vocab_sorted :\n",
    "    if frequency > 1:\n",
    "        i += 1\n",
    "        word_to_index[word] = i\n",
    "    \n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'natural': 1, 'language': 2, 'processing': 3, '\\n': 4, 'nlp': 5, 'post': 6, 'OOV': 7}\n"
     ]
    }
   ],
   "source": [
    "word_to_index['OOV'] = len(word_to_index) + 1\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nlp', ' \\n', 'natural', 'language', 'processing', 'nlp', 'short', 'broadly', 'define', 'automatic', 'manipulation', 'natural', 'language', 'like', 'speech', 'text', 'software', '\\n', 'study', 'natural', 'language', 'processing', 'around', '50', 'year', 'grow', 'field', 'linguistic', 'rise', 'computer', '\\n', 'post', 'discover', 'natural', 'language', 'processing', 'important', '\\n', 'read', 'post', 'know', ' ', 'natural', 'language', 'different', 'type', 'datum']\n",
      "[5, 7, 1, 2, 3, 5, 7, 7, 7, 7, 7, 1, 2, 7, 7, 7, 7, 4, 7, 1, 2, 3, 7, 7, 7, 7, 7, 7, 7, 7, 4, 6, 7, 1, 2, 3, 7, 4, 7, 6, 7, 7, 1, 2, 7, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "encoded = []\n",
    "\n",
    "print(rmv_sw_sentence)\n",
    "\n",
    "for w in rmv_sw_sentence:\n",
    "   encoded.append(word_to_index.get(w, word_to_index['OOV']))\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE END ðŸŒŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
